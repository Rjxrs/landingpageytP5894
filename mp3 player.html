<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Audio Visualizer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        /* Basic styling for body and canvas */
        body {
            margin: 0;
            overflow: hidden; /* Prevent scrollbars */
            background-color: #000; /* Start with black background */
            color: #fff;
            font-family: 'Inter', sans-serif; /* Use Inter font */
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start; /* Align content to the top */
            min-height: 100vh;
        }
        #visualizer-canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1; /* Place canvas behind other content */
        }
        /* Style the controls container */
        .controls-container {
            background-color: rgba(30, 30, 30, 0.8); /* Semi-transparent dark background */
            padding: 20px;
            border-radius: 12px; /* Rounded corners */
            margin-top: 50px; /* Space from the top */
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 15px; /* Space between elements */
            z-index: 10; /* Ensure controls are above canvas */
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.5);
            max-width: 90%;
            width: 500px; /* Fixed width for the container */
        }
        /* Style the file input label */
        label[for="audio-file-input"] {
            display: block;
            padding: 10px 15px;
            border-radius: 8px;
            border: 1px solid #444;
            background-color: #007bff; /* Blue background for button-like appearance */
            color: #fff;
            font-size: 1rem;
            cursor: pointer;
            text-align: center;
            transition: background-color 0.2s ease;
            width: 100%; /* Make label take full width */
        }
        label[for="audio-file-input"]:hover {
            background-color: #0056b3;
        }
        /* Hide the actual file input visually but keep accessible */
        #audio-file-input {
            width: 0.1px;
            height: 0.1px;
            opacity: 0;
            overflow: hidden;
            position: absolute;
            z-index: -1;
        }
         /* Style the audio element */
        audio {
            width: 100%;
             /* Style default controls to be visible on dark background */
            filter: invert(1) sepia(1) saturate(5) hue-rotate(180deg);
            border-radius: 8px;
            margin-top: 10px; /* Add some space above audio controls */
        }
        /* Style the info text */
        .info-text {
            font-size: 0.9rem;
            color: #aaa;
            text-align: center;
        }
        #loading-message {
            color: #ccc;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="controls-container rounded-lg shadow-lg">
        <h1 class="text-2xl font-bold mb-2 text-center">Audio Visualizer</h1>

        <label for="audio-file-input">Choose an Audio File</label>
        <input type="file" id="audio-file-input" accept="audio/*">

        <p id="loading-message" class="info-text">Please select an audio file.</p>

        <audio id="audio-source" controls crossorigin="anonymous" class="w-full rounded"></audio>

    </div>

    <canvas id="visualizer-canvas"></canvas>

    <script>
        // --- Global Variables ---
        let scene, camera, renderer;
        let audioContext, analyser, source, dataArray, bufferLength; // Make audio variables global
        const bars = []; // Array to hold the visualizer bars
        const NUM_BARS = 128; // Number of bars in the visualizer
        let isAudioContextInitialized = false; // Flag to track initialization

        // --- Initialization ---
        function init() {
            // 1. Set up Three.js Scene, Camera, Renderer
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 50; // Move camera back

            renderer = new THREE.WebGLRenderer({ canvas: document.getElementById('visualizer-canvas'), alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setClearColor(0x000000, 1); // Black background initially

            // 2. Create Visualizer Bars
            const barWidth = 0.5;
            const spacing = 0.2;
            const totalWidth = (barWidth + spacing) * NUM_BARS;
            const startX = -totalWidth / 2 + barWidth / 2;

            const geometry = new THREE.BoxGeometry(barWidth, 1, barWidth);
            // Use MeshPhongMaterial for better lighting interaction
            const material = new THREE.MeshPhongMaterial({
                 color: 0x00ffcc, // Teal color
                 emissive: 0x005566, // Darker emissive, light comes mainly from PointLight
                 specular: 0x111111, // Small specular highlight
                 shininess: 50,     // Moderate shininess
                 side: THREE.DoubleSide // Render both sides (optional)
            });

            for (let i = 0; i < NUM_BARS; i++) {
                // Clone material for each bar to allow individual color changes
                const barMaterial = material.clone();
                const bar = new THREE.Mesh(geometry, barMaterial);
                bar.position.x = startX + i * (barWidth + spacing);
                bar.scale.y = 0.1; // Start very small
                scene.add(bar);
                bars.push(bar);
            }

            // 3. Add Lighting
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.3); // Slightly brighter ambient
            scene.add(ambientLight);
            const pointLight = new THREE.PointLight(0x00ccff, 0.8, 300); // Cyan point light
            pointLight.position.set(0, 30, 40);
            scene.add(pointLight);
            const pointLight2 = new THREE.PointLight(0xff6600, 0.5, 300); // Orange point light from side
            pointLight2.position.set(-40, 10, 20);
            scene.add(pointLight2);


            // 4. Set up File Input Listener (Audio Context setup moved here)
            setupFileInputListener();

            // 5. Start Animation Loop
            animate();

            // 6. Handle Window Resize
            window.addEventListener('resize', onWindowResize, false);
        }

        // --- Web Audio API Setup (Called after file selection) ---
        function setupAudioContextAndSource(audioElement) {
            if (isAudioContextInitialized) return; // Prevent re-initialization

            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();

                // Create analyser node
                analyser = audioContext.createAnalyser();
                analyser.fftSize = NUM_BARS * 2;
                bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);

                // Create media element source node AFTER user interaction (file select)
                source = audioContext.createMediaElementSource(audioElement);

                // Connect the nodes: source -> analyser -> destination (speakers)
                source.connect(analyser);
                analyser.connect(audioContext.destination);

                isAudioContextInitialized = true; // Mark as initialized
                console.log("AudioContext Initialized and Source Connected");

                // Attempt to resume context if suspended (needed for autoplay restrictions)
                 const resumeContext = () => {
                    if (audioContext.state === 'suspended') {
                        audioContext.resume().then(() => {
                            console.log("AudioContext Resumed");
                        }).catch(e => console.error("Error resuming AudioContext:", e));
                    }
                    // Clean up listeners after first successful resume/play
                    audioElement.removeEventListener('play', resumeContext);
                    document.body.removeEventListener('click', resumeContext);
                };

                // Listen for play event on audio element OR first click on body
                audioElement.addEventListener('play', resumeContext);
                document.body.addEventListener('click', resumeContext, { once: true }); // Use once for body click


            } catch (e) {
                console.error("Error setting up Web Audio API:", e);
                document.getElementById('loading-message').textContent = "Error initializing audio. Please try refreshing.";
                alert("Web Audio API error: " + e.message);
            }
        }

        // --- File Input Listener ---
        function setupFileInputListener() {
            const fileInput = document.getElementById('audio-file-input');
            const audioElement = document.getElementById('audio-source');
            const loadingMessage = document.getElementById('loading-message');

            fileInput.addEventListener('change', function(event) {
                const files = event.target.files;
                if (files.length > 0) {
                    const file = files[0];
                    const objectURL = URL.createObjectURL(file);

                    // Set the audio source
                    audioElement.src = objectURL;
                    // audioElement.load(); // Load the new source

                    loadingMessage.textContent = `Loaded: ${file.name}. Press play!`;
                    console.log("Audio file loaded:", file.name);

                    // --- IMPORTANT: Setup Audio Context HERE ---
                    // This ensures it's done after user interaction (selecting the file)
                    // and the audio element has a valid src.
                    if (!isAudioContextInitialized) {
                        setupAudioContextAndSource(audioElement);
                    }

                    // Revoke the object URL when the audio element starts playing a new source
                    // or when the page unloads to free up memory.
                    audioElement.onloadedmetadata = () => {
                      // Optional: could revoke previous URL here if needed
                    };
                    window.addEventListener('beforeunload', () => {
                        URL.revokeObjectURL(objectURL);
                    });

                } else {
                    loadingMessage.textContent = "No file selected.";
                }
            });
        }


        // --- Animation Loop ---
        function animate() {
            requestAnimationFrame(animate); // Loop the animation

            // Only update if analyser and dataArray are ready
            if (analyser && dataArray) {
                analyser.getByteFrequencyData(dataArray); // Get frequency data

                // Update bar heights and colors based on frequency data
                bars.forEach((bar, i) => {
                    const frequencyValue = dataArray[i]; // Value from 0 to 255
                    const scale = (frequencyValue / 255) * 50 + 0.1; // Normalize, scale, add minimum height

                    // Smooth the transition using lerp (linear interpolation)
                    bar.scale.y += (scale - bar.scale.y) * 0.15;

                    // Adjust position so scaling happens from the bottom (centered on XZ plane)
                    bar.position.y = bar.scale.y / 2 - 10; // Offset slightly down

                    // Change color based on height/frequency value
                    // Map frequency value (0-255) to hue (e.g., blue -> green -> red)
                    const hue = (1 - (frequencyValue / 255)) * 0.66; // 0.66 (blue) down to 0 (red)
                    bar.material.color.setHSL(hue, 0.9, 0.6); // Saturation 0.9, Lightness 0.6
                    // Make emissive color stronger for higher frequencies
                    bar.material.emissive.setHSL(hue, 0.8, Math.min(0.5, (frequencyValue / 255) * 0.5));
                });

                // Optional: Rotate the camera slowly for a dynamic view
                 camera.position.x = Math.sin(Date.now() * 0.00015) * 15; // Slower rotation, wider arc
                 camera.position.z = 50 + Math.cos(Date.now() * 0.00015) * 15;
                 camera.lookAt(0, -5, 0); // Keep camera focused slightly below center of bars
            }

            renderer.render(scene, camera); // Render the scene
        }

        // --- Window Resize Handler ---
        function onWindowResize() {
            if (camera && renderer) {
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(window.innerWidth, window.innerHeight);
            }
        }

        // --- Start Everything ---
        // Run init when the window is fully loaded
        window.onload = init;

    </script>
</body>
</html>
